{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # \"Header\"\n",
    "\n",
    "<p style=\"text-align: left;  font-size:18pt; LINE-HEIGHT:30px;\">\n",
    "    <span style=\"float: left\">\n",
    "     Technische Hochschule Ingolstadt<br>\n",
    "     Prof. Dr. Sören Gröttrup<br>\n",
    "     Laura Dietl\n",
    "    </span>\n",
    "    <span style=\"float: right;\">\n",
    "       Machine Learning 1<br>\n",
    "        <span style=\"float: right;\">WS 24/25</span>\n",
    "    </span>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # \"Header Aufgabenblatt\"\n",
    "<br>\n",
    "<p style=\"text-align: center;  font-size:18pt; LINE-HEIGHT:30px;\">\n",
    "     <span style=\"font-weight: bold;\">Aufgabenblatt 5</span><br>\n",
    "     Themen: ROC<br>\n",
    "     Abgabetermin: 13.12.2024, 23:59 Uhr <br>\n",
    "    Punkte: 20\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Namen:** Emelie Hauck, Conrad Christoph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1.1 [10 Punkte]\n",
    "1. Schreiben Sie eine Funktion `calc_roc(y_labels, pred_prob)`, welche die Werte der ROC-Kurve (FPR, TPR , threshold) für ein binäre Klassifikation berechnet und diese zurückgibt. Die Eingaben `y_labels` enthält dabei die wahren Werte eine Zielvariablen und `pred_pob` ist ein Verktor mit Wahrscheinlichkeiten für die Zugehörigkeit des jeweiligen Sample zur positiven Klassen. Beispiele sind unterhalb der Aufgabe angegeben.\n",
    "1. Erweitern Sie die Funktion so, dass sie zusätzlich den AUC berechnet und diesen ebenfalls zurückgibt, sprich `roc_values, auc = calc_roc(y_labels, pred_prob)`\n",
    "1. Plotten Sie die ROC-Kurve für die unten agegebenen Vektoren `y_labels` und `pred_prob` und berechnen Sie die AUC\n",
    "1. Bei welchen Schwellwert (Threshold) für die Entscheidung ob ein Sample zur Klasse 1 gehört ist die Accuracy am größten?\n",
    "\n",
    "_Hinweis:_ \n",
    "* Für die Aufgabe dürfen Sie nicht die von Python (sklearn) bereitgestellten Funktionen für die Berechnung des roc und auc verwenden, sondern sollen diese selbständig entwickeln.\n",
    "* Python stellt die Funktion `sklearn.metrics.roc_curve` zur Berechnung der TPR und FPR zur Verfügung. Sie können diese Funktion als Kontrolle nutzen, um die Richtigkeit Ihrer Berechnungen zu verifizieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_labels = np.load(file=\"Daten Blatt 5/target.npy\")\n",
    "pred_prob = np.load(file=\"Daten Blatt 5/pred.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.97774845e-01 9.95735795e-01 9.93515061e-01 9.93358040e-01\n",
      " 9.92338916e-01 9.91180568e-01 9.90418743e-01 9.90341936e-01\n",
      " 9.90145578e-01 9.89323108e-01 9.87427675e-01 9.87346618e-01\n",
      " 9.87018367e-01 9.86417092e-01 9.86178377e-01 9.86004312e-01\n",
      " 9.85891181e-01 9.85862706e-01 9.85415984e-01 9.85224815e-01\n",
      " 9.84506017e-01 9.84376649e-01 9.84224417e-01 9.83915331e-01\n",
      " 9.83729366e-01 9.83693560e-01 9.83139249e-01 9.82085725e-01\n",
      " 9.80832341e-01 9.79313109e-01 9.79233315e-01 9.79168920e-01\n",
      " 9.78645790e-01 9.78564089e-01 9.77927616e-01 9.76764826e-01\n",
      " 9.76339259e-01 9.75890746e-01 9.75770238e-01 9.75587375e-01\n",
      " 9.74699016e-01 9.74655534e-01 9.74150887e-01 9.72992370e-01\n",
      " 9.72067357e-01 9.72053444e-01 9.71765709e-01 9.70845918e-01\n",
      " 9.70606677e-01 9.69287732e-01 9.69255765e-01 9.69010297e-01\n",
      " 9.67570941e-01 9.67553122e-01 9.67148703e-01 9.66603209e-01\n",
      " 9.66362429e-01 9.65982597e-01 9.65777175e-01 9.64575766e-01\n",
      " 9.64145289e-01 9.64038410e-01 9.63456563e-01 9.62875675e-01\n",
      " 9.62131626e-01 9.61978979e-01 9.61875517e-01 9.61870179e-01\n",
      " 9.60846420e-01 9.59329545e-01 9.58524954e-01 9.58265631e-01\n",
      " 9.58118683e-01 9.57887183e-01 9.57175462e-01 9.56495941e-01\n",
      " 9.56108189e-01 9.55528995e-01 9.54252422e-01 9.53316361e-01\n",
      " 9.50620936e-01 9.50420457e-01 9.49756181e-01 9.48558698e-01\n",
      " 9.47676783e-01 9.46201767e-01 9.44874163e-01 9.44828388e-01\n",
      " 9.44446732e-01 9.43959654e-01 9.43763085e-01 9.41645110e-01\n",
      " 9.37773885e-01 9.37594766e-01 9.36430285e-01 9.33105441e-01\n",
      " 9.32951876e-01 9.31642265e-01 9.31026207e-01 9.30395158e-01\n",
      " 9.29386298e-01 9.28859197e-01 9.23897039e-01 9.22978053e-01\n",
      " 9.19695569e-01 9.19308443e-01 9.19281823e-01 9.17844623e-01\n",
      " 9.17821756e-01 9.12787844e-01 9.11385698e-01 9.11116192e-01\n",
      " 9.09075648e-01 9.06903148e-01 9.05368305e-01 9.01204102e-01\n",
      " 8.99761618e-01 8.97011291e-01 8.95024879e-01 8.92814997e-01\n",
      " 8.90780056e-01 8.86755153e-01 8.84759637e-01 8.80257270e-01\n",
      " 8.74908004e-01 8.72419066e-01 8.71885406e-01 8.67052225e-01\n",
      " 8.65873673e-01 8.64490819e-01 8.63628263e-01 8.60903014e-01\n",
      " 8.48894576e-01 8.41446888e-01 8.39390708e-01 8.26737219e-01\n",
      " 8.26221017e-01 8.20381357e-01 8.17521536e-01 8.09165467e-01\n",
      " 8.08027024e-01 7.86832421e-01 7.81519680e-01 7.80678809e-01\n",
      " 7.80235929e-01 7.78291569e-01 7.71474505e-01 7.69890601e-01\n",
      " 7.58186902e-01 7.55958035e-01 7.44831667e-01 7.38871366e-01\n",
      " 7.34827690e-01 7.28666895e-01 7.17917236e-01 7.15295232e-01\n",
      " 7.12887369e-01 7.08561129e-01 7.04177863e-01 6.98935929e-01\n",
      " 6.96612628e-01 6.95528859e-01 6.80677909e-01 6.75900398e-01\n",
      " 6.65961272e-01 6.58840636e-01 6.56560201e-01 6.54704489e-01\n",
      " 6.38081173e-01 6.17111225e-01 6.07955791e-01 6.03722016e-01\n",
      " 5.96872124e-01 5.84237314e-01 5.68693497e-01 5.66557726e-01\n",
      " 5.58763228e-01 5.53393986e-01 4.82878003e-01 4.68159997e-01\n",
      " 4.07579528e-01 3.60457784e-01 3.42854572e-01 3.32817369e-01\n",
      " 3.03998408e-01 2.92275327e-01 2.68178709e-01 2.31230959e-01\n",
      " 2.22339547e-01 2.09543555e-01 1.89359867e-01 1.88162538e-01\n",
      " 1.87027967e-01 1.85895995e-01 1.80589182e-01 1.49723365e-01\n",
      " 1.47715570e-01 1.34398608e-01 1.19460959e-01 1.10690278e-01\n",
      " 1.01928611e-01 7.84040273e-02 7.56824224e-02 5.95317790e-02\n",
      " 3.47699741e-02 2.02705535e-02 1.83555131e-02 1.59425442e-02\n",
      " 1.58862661e-02 1.51961379e-02 1.50976087e-02 1.44647178e-02\n",
      " 1.30005916e-02 1.12230083e-02 6.92779929e-03 5.52136151e-03\n",
      " 4.43166124e-03 3.94510545e-03 3.09939869e-03 2.65593348e-03\n",
      " 2.54719193e-03 2.29850317e-03 2.27760698e-03 2.21056508e-03\n",
      " 2.15103304e-03 2.04211764e-03 1.97501137e-03 1.12289143e-03\n",
      " 7.87850124e-04 6.32384896e-04 5.92547940e-04 5.66775138e-04\n",
      " 5.39910425e-04 5.36353355e-04 5.36237513e-04 3.94636866e-04\n",
      " 2.17989764e-04 1.64280690e-04 5.93921254e-05 3.71933316e-05\n",
      " 3.12662950e-05 2.49934569e-05 2.44888261e-05 1.47469457e-05\n",
      " 9.97929044e-06 9.43168389e-06 8.12386334e-06 6.56403386e-06\n",
      " 4.34076478e-06 4.23084770e-06 4.09336572e-06 4.07163887e-06\n",
      " 3.74275232e-06 2.03568317e-06 1.24796505e-06 1.11501539e-06\n",
      " 7.46410132e-07 5.72991903e-07 4.68806857e-07 3.91328165e-07\n",
      " 2.33421097e-07 2.04491038e-07 1.94168905e-07 8.04866381e-08\n",
      " 6.31934669e-08 4.96046789e-08 4.35464149e-08 2.63089111e-09\n",
      " 2.19708632e-09 1.80913093e-09 1.19036226e-09 8.31253887e-10\n",
      " 3.92624340e-11 3.36256122e-11 3.22076956e-11 2.66696324e-11\n",
      " 1.50033359e-11 1.39141084e-11 1.52867949e-12 3.29634011e-13\n",
      " 2.54365415e-15 3.41097528e-16 2.14904535e-16 6.12464352e-17\n",
      " 1.85443835e-18 4.89974566e-19 1.16768351e-19 2.10702718e-20\n",
      " 2.81747061e-21 5.38476803e-29 1.27245112e-33 1.65229096e-36]\n",
      "[0.         0.00806452 0.01209677 0.01612903 0.01612903 0.02016129\n",
      " 0.02822581 0.03225806 0.03629032 0.04435484 0.05241935 0.05645161\n",
      " 0.06048387 0.06451613 0.06854839 0.07258065 0.08467742 0.08870968\n",
      " 0.09274194 0.10080645 0.10483871 0.11693548 0.125      0.12903226\n",
      " 0.13306452 0.13709677 0.14516129 0.14919355 0.15725806 0.16129032\n",
      " 0.16129032 0.16532258 0.16935484 0.1733871  0.17741935 0.18548387\n",
      " 0.18951613 0.19354839 0.2016129  0.20564516 0.20967742 0.20967742\n",
      " 0.21370968 0.22177419 0.22983871 0.23387097 0.24193548 0.24596774\n",
      " 0.25       0.25403226 0.25806452 0.25806452 0.26209677 0.26612903\n",
      " 0.27419355 0.27822581 0.28225806 0.28629032 0.29032258 0.29032258\n",
      " 0.29435484 0.2983871  0.30241935 0.30645161 0.31451613 0.32258065\n",
      " 0.3266129  0.33064516 0.33467742 0.33870968 0.34274194 0.35080645\n",
      " 0.35887097 0.36290323 0.36693548 0.37096774 0.375      0.37903226\n",
      " 0.37903226 0.38709677 0.39112903 0.39919355 0.40322581 0.41935484\n",
      " 0.4233871  0.43145161 0.43951613 0.44354839 0.44758065 0.4516129\n",
      " 0.45967742 0.45967742 0.46774194 0.47580645 0.47983871 0.48790323\n",
      " 0.48790323 0.49596774 0.5        0.50403226 0.50806452 0.51209677\n",
      " 0.51612903 0.52016129 0.52419355 0.53225806 0.54032258 0.5483871\n",
      " 0.55241935 0.55645161 0.56451613 0.57258065 0.5766129  0.58467742\n",
      " 0.59274194 0.59677419 0.60080645 0.60887097 0.61290323 0.61693548\n",
      " 0.625      0.62903226 0.62903226 0.62903226 0.63709677 0.64112903\n",
      " 0.64919355 0.66129032 0.66532258 0.66935484 0.67741935 0.68548387\n",
      " 0.69354839 0.7016129  0.70564516 0.70967742 0.72177419 0.72580645\n",
      " 0.72983871 0.74193548 0.74596774 0.75       0.75403226 0.75806452\n",
      " 0.76612903 0.77016129 0.77419355 0.77822581 0.78225806 0.78629032\n",
      " 0.79032258 0.79032258 0.79435484 0.7983871  0.80241935 0.80645161\n",
      " 0.80645161 0.81854839 0.8266129  0.83064516 0.83467742 0.84274194\n",
      " 0.84274194 0.84677419 0.85483871 0.85483871 0.85483871 0.85483871\n",
      " 0.86693548 0.875      0.87903226 0.88709677 0.89112903 0.90322581\n",
      " 0.90725806 0.91532258 0.91935484 0.9233871  0.92741935 0.92741935\n",
      " 0.93145161 0.93951613 0.93951613 0.94354839 0.94354839 0.9516129\n",
      " 0.95564516 0.95564516 0.95564516 0.95564516 0.95564516 0.96370968\n",
      " 0.96774194 0.97177419 0.97177419 0.97177419 0.97580645 0.97983871\n",
      " 0.97983871 0.97983871 0.98790323 0.98790323 0.98790323 0.99596774\n",
      " 0.99596774 0.99596774 0.99596774 0.99596774 0.99596774 0.99596774\n",
      " 0.99596774 0.99596774 0.99596774 0.99596774 0.99596774 0.99596774\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.        ]\n",
      "0.9310006366723259\n",
      "0.06899936332767402\n"
     ]
    }
   ],
   "source": [
    "#### Code HERE ####\n",
    "\n",
    "def get_single_tpr_fpr(df):\n",
    "\n",
    "    '''\n",
    "    Note, this implementation is only for binaly class labels (0 and 1)\n",
    "    :param df: the dataframe should have 'y' and 'y_predicted' as its labels\n",
    "    :return: a list containing tpr and fpr\n",
    "    '''\n",
    "\n",
    "    tp = ((df['y'] == 1.0 ) & (df['y_predicted'] == 1)).sum()\n",
    "    fp = ((df['y'] == 0.0 ) & (df['y_predicted'] == 1)).sum()\n",
    "    tn = ((df['y'] == 0.0 ) & (df['y_predicted'] == 0)).sum()\n",
    "    fn = ((df['y'] == 1.0 ) & (df['y_predicted'] == 0)).sum()\n",
    "\n",
    "    tpr = tp / (tp + fn )\n",
    "    fpr = fp / (fp + tn)\n",
    "\n",
    "    return [tpr, fpr]\n",
    "\n",
    "\n",
    "# While computing AUC score you need to calculate \"TP,\"FP\" at every threshold by using actual \"y\" and predicted \"y_pred\".\n",
    "\n",
    "def calculate_all_thresholds_tpr_fpr_arr(df_original):\n",
    "\n",
    "    '''\n",
    "\n",
    "    :param df_original: the original dataframe, which should have a 'proba' label\n",
    "    :return: two arrays, tpr_arr_for_all_thresholds, fpr_arr_for_all_thresholds\n",
    "    '''\n",
    "\n",
    "    tpr_arr_for_all_thresholds = []\n",
    "    fpr_arr_for_all_thresholds = []\n",
    "\n",
    "    sorted_df = df_original.sort_values(by=['proba'], ascending=False)\n",
    "\n",
    "    unique_probability_thresholds = sorted_df['proba'].unique()\n",
    "\n",
    "    for threshold in tqdm(unique_probability_thresholds):\n",
    "        sorted_df['y_predicted'] = np.where(sorted_df['proba'] >= threshold, 1, 0)\n",
    "        tpr_fpr_arr = get_single_tpr_fpr(sorted_df)\n",
    "        tpr_arr_for_all_thresholds.append(tpr_fpr_arr[0])\n",
    "        fpr_arr_for_all_thresholds.append(tpr_fpr_arr[1])\n",
    "\n",
    "    return tpr_arr_for_all_thresholds, fpr_arr_for_all_thresholds\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def cal_roc(y_labels, pred_prob):\n",
    "    \n",
    "    thresholds = np.unique(pred_prob)[::-1]\n",
    "    print(thresholds)\n",
    "    tprs = []\n",
    "    fprs = []\n",
    "    for theta in thresholds:\n",
    "        pred = (pred_prob >= theta).astype(int)\n",
    "        \n",
    "        TP = np.sum((pred == 1) & (y_labels == 1))\n",
    "        FP = np.sum((pred == 1) & (y_labels == 0))\n",
    "        TN = np.sum((pred == 0) & (y_labels == 0))\n",
    "        FN = np.sum((pred == 0) & (y_labels == 1))\n",
    "    \n",
    "        TPR = TP / (TP + FN) #if (TP + FN) > 0 else 0\n",
    "        FPR = FP / (FP + TN) #if (FP + TN) > 0 else 0\n",
    "\n",
    "        tprs.append(TPR)\n",
    "        fprs.append(FPR)\n",
    "    \n",
    "    control_fprs, control_tprs, control_thresholds = roc_curve(y_labels, pred_prob)\n",
    "\n",
    "    tprs = np.array(tprs)\n",
    "    print(tprs)\n",
    "    fprs = np.array(fprs)\n",
    "    thresholds = np.array(thresholds)\n",
    "\n",
    "    tpr_diff = np.diff(tprs)\n",
    "    fpr_diff = np.diff(fprs)\n",
    "\n",
    "    auc = np.sum(tprs[:-1] * fpr_diff) + 0.5 * np.sum(fpr_diff * (tpr_diff + tprs[:-1]))\n",
    "    auc = np.trapz(fprs[::-1], tprs[::-1])\n",
    "    auc_control = roc_auc_score(y_labels, pred_prob)\n",
    "    print(auc_control)\n",
    "\n",
    "    return (tprs, fprs, thresholds), auc\n",
    "\n",
    "\n",
    "roc_val, auc = cal_roc(y_labels, pred_prob)\n",
    "print(auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1.2 [10 Punkte]\n",
    "\n",
    "**Daten:** Der Datensatz `creditcard_small.csv` ist ein gekürzter Datensatz mit weniger Variablen von dem Original-Datensatz https://www.kaggle.com/mlg-ulb/creditcardfraud. Er enthält anonymisierte Informationen von Kreditkartentransaktionen und ein Label `Class`, ob diese Transaktion betrügerisch war (`Class=1`), oder nicht (`Class=2`).\n",
    "\n",
    "1. Trainieren Sie das Logistisches-Regrassionsmodell `log_reg = LogisticRegression()` (siehe Code unten) auf den Trainingsdaten `x_train, y_train` und machen Sie damit eine Vorhersage für die Testdaten `x_test`.\n",
    "1. Berechnen Sie diverse Evaluationsmetriken für de Performance des Modells auf den Testdaten mittels einen Klassifikations-Report durch die Funktion `classification_report` aus dem Modul `sklearn.metrics`. Was ist die Accuracy, Precision, Sensitivity, Specificity und F1-Score für das Modell?\n",
    "1. Berechnen Sie die AUC und plotten Sie die ROC-Kurve für die Testdaten. Interpretieren Sie dessen Verlauf. Sie können hier die Funktionen `sklearn.metrics.roc_curve` und `sklearn.metrics.roc_auc_score` benutzen.\n",
    "1. Trainieren Sie das Neuronale Netz `nn = MLPClassifier(activation=\"relu\")` auf den Trainigsdaten `x_train, y_train`. Wie ist die AUC bei diesem Modell auf den Testdaten? Plotten Sie auch hier die ROC-Kurve und vergleichen Sie diese mit der der Logistischen Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vorgeschriebener Code. Bitte nicht verändern**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284802</th>\n",
       "      <td>-5.364473</td>\n",
       "      <td>-2.606837</td>\n",
       "      <td>-4.918215</td>\n",
       "      <td>7.305334</td>\n",
       "      <td>0.943651</td>\n",
       "      <td>0.823731</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284803</th>\n",
       "      <td>0.868229</td>\n",
       "      <td>1.058415</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.294869</td>\n",
       "      <td>0.068472</td>\n",
       "      <td>-0.053527</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284804</th>\n",
       "      <td>2.630515</td>\n",
       "      <td>3.031260</td>\n",
       "      <td>-0.296827</td>\n",
       "      <td>0.708417</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>-0.026561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284805</th>\n",
       "      <td>-0.377961</td>\n",
       "      <td>0.623708</td>\n",
       "      <td>-0.686180</td>\n",
       "      <td>0.679145</td>\n",
       "      <td>0.108821</td>\n",
       "      <td>0.104533</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284806</th>\n",
       "      <td>-0.012546</td>\n",
       "      <td>-0.649617</td>\n",
       "      <td>1.577006</td>\n",
       "      <td>-0.414650</td>\n",
       "      <td>-0.002415</td>\n",
       "      <td>0.013649</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>284807 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V5        V6        V7        V8       V27       V28  Class\n",
       "0      -0.338321  0.462388  0.239599  0.098698  0.133558 -0.021053      0\n",
       "1       0.060018 -0.082361 -0.078803  0.085102 -0.008983  0.014724      0\n",
       "2      -0.503198  1.800499  0.791461  0.247676 -0.055353 -0.059752      0\n",
       "3      -0.010309  1.247203  0.237609  0.377436  0.062723  0.061458      0\n",
       "4      -0.407193  0.095921  0.592941 -0.270533  0.219422  0.215153      0\n",
       "...          ...       ...       ...       ...       ...       ...    ...\n",
       "284802 -5.364473 -2.606837 -4.918215  7.305334  0.943651  0.823731      0\n",
       "284803  0.868229  1.058415  0.024330  0.294869  0.068472 -0.053527      0\n",
       "284804  2.630515  3.031260 -0.296827  0.708417  0.004455 -0.026561      0\n",
       "284805 -0.377961  0.623708 -0.686180  0.679145  0.108821  0.104533      0\n",
       "284806 -0.012546 -0.649617  1.577006 -0.414650 -0.002415  0.013649      0\n",
       "\n",
       "[284807 rows x 7 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data\n",
    "data = pd.read_csv(\"Daten Blatt 5/creditcard_small.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "data_train, data_test = train_test_split(data, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train.Class\n",
    "x_train = data_train.drop(columns=[\"Class\"])\n",
    "\n",
    "y_test = data_test.Class\n",
    "x_test = data_test.drop(columns=[\"Class\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "log_reg = LogisticRegression()\n",
    "nn = MLPClassifier(activation=\"relu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ihren Code ab hier einfügen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CODE HERE ####\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
