{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # \"Header\"\n",
    "\n",
    "<p style=\"text-align: left;  font-size:18pt; LINE-HEIGHT:30px;\">\n",
    "    <span style=\"float: left\">\n",
    "     Technische Hochschule Ingolstadt<br>\n",
    "     Prof. Dr. Sören Gröttrup <br>\n",
    "     Laura Dietl\n",
    "    </span>\n",
    "    <span style=\"float: right;\">\n",
    "       Machine Learning 2<br>\n",
    "        <span style=\"float: right;\">SS 2025</span>\n",
    "    </span>\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # \"Header Aufgabenblatt\"\n",
    "<br>\n",
    "<p style=\"text-align: center;  font-size:18pt; LINE-HEIGHT:30px;\">\n",
    "     <span style=\"font-weight: bold;\">Aufgabenblatt 1</span><br>\n",
    "     Themen: Mini-Batch, Lernrate, Konvergenz<br>\n",
    "     Abgabetermin: 03.04.2025, 23:59 Uhr <br>\n",
    "     Punkte: 24\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Namen:** Emelie Hauck, Conrad Christoph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten\n",
    "Der Datensatz `gt.csv` (zu finden auf der Moodle-Seite des Praktikums (https://moodle.thi.de/course/view.php?id=6824)) ist eine etwas abgewandelte und bearbeitete Version des Datensatzes aus dem UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/Gas+Turbine+CO+and+NOx+Emission+Data+Set). \n",
    "\n",
    "Der Datensatz enthält 36733 Messpunkte von je 11 Sensoren einer Gasturbine im Nordwesten der Türkei. Die einzelnen Werte sind dabei jeweils Aggregate (Summe oder Mittelwert) über eine Stunde. Die Sensordaten diesen dazu die Gasemissionender Turbine, insb. CO und NOx (NO & NO2), zu messen.\n",
    "\n",
    "Das File `gt_norm` enthält bereits den normierten udn aufbereiteten Datensatz, geplittet in Training und Test. Die Daten liegen jeweils bereits als TensorDataset bereit und können direkt mit einem DataLoader verarbeitet werden.\n",
    "\n",
    "## Ziel des Aufgabenblattes\n",
    "Trainieren Sie mehrere Neuronale Netze für unterschiedliche Batch-Größen und Lernraten, um ein besseres Verständnis davon zu bekommen, was diese Hyperparameter für einen Einfluss auf das Lernen haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "import time\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "file_path = \"./Daten Blatt 1/gt_norm\"\n",
    "data = torch.load(file_path, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data.get(\"train_data\")\n",
    "test_data = data.get(\"test_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.utils.data.dataset.TensorDataset,\n",
       " torch.utils.data.dataset.TensorDataset)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data), type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Größe des Trainingssets:  29386\n",
      "Größe des Testsets:  7347\n"
     ]
    }
   ],
   "source": [
    "# Größe des Trainings und Testset\n",
    "print(\"Größe des Trainingssets: \", len(train_data))\n",
    "print(\"Größe des Testsets: \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl an Feature:  9\n"
     ]
    }
   ],
   "source": [
    "# Anzahl an Feature\n",
    "nfeatures = len(train_data[0][0])\n",
    "print(\"Anzahl an Feature: \", nfeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Batches in PyTorch / DataLoader\n",
    "\n",
    "Die Einteilung eines Datensatzes in (Mini-)Batches kann über den so genannten `DataLoader` und folgenden Code erfolgen:\n",
    "\n",
    "```python\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "      train_data,\n",
    "      batch_size=b, shuffle=True)\n",
    "```\n",
    "\n",
    "Ein TensorDataset (hier `train_data`) wird dabei in Batches gleicher Größe (hier `b`) eingeteilt. Der Parameter `shuffle=True` garantiert, dass in jeder Epoche die Einteilung in die Mini-Batches neu gezogen wird. In jeder Epoche haben wir also unterschiedliche Mini-Batches.\n",
    "\n",
    "Zurückgegeben wrid ein iterierbares Objekt (`train_loader`). Mittels einer `for`-Schleife kann jetzt über die Batches iteriert werden und für einen Batch das Gradientenabstiegsverfahren durchgeführt werden.\n",
    "\n",
    "**Iteration über die Batches**\n",
    "```python\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    ...\n",
    "```\n",
    "\n",
    "`data` ist der Tensor mit den Features und `target` der Tensor der Zielvariable für die Sampels des jeweiligen Mini-Batches. `batch_idx` ist nur der Index des jeweiligen Batches in der Epoche."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1 (Batch-Size und Learnrate) [18 Punkte]\n",
    "In dieser Aufgabe sollen Sie ein Neuronales Netz trainieren mit unterschiedlicher Auswahl an Batch-Größe sowie Lernrate, und analysieren was dies für Auswirkungen auf das Lernen hat.\n",
    "\n",
    "1. Definieren Sie ein Neuronales Netz `Net()`. Das Netz soll dabei 2 Hidden-Layer haben, jeweils mit ReLU-Aktivierungsfunktion. Die Anzahl der Neuronen der Hidden-Layer ist 16 und 8.\n",
    "1. Schreiben eine Funktion `train(network, train_loader)`, welche das Neuronale Netz `network` über eine Epoche mittel des Mini-Batch Verfahrens trainiert. `train_loader` ist dabei der  DataLoader für dieMini-Batch Einteilung.\n",
    "1. Schreiben Sie eine Funktion `calc_loss(network, data_loader)`, welche für eine Neuronales Netz `network` den mittleren quadratischen Fehler (MSE) für die Daten, welche mittels DataLoader `data_loader` übergeben werden, bestimmt.\n",
    "1. Trainieren Sie das Neuronale Netz `Net()` aus 1. mittels Gradientenabstieg `torch.optim.SGD()` nach dem Batch-Verfahren auf den obigen Daten `gt`. Verwenden Sie als Lernrate `learning_rate = 0.001` und als Verlustfunktion den L2-Loss. Wie groß ist der MSE für Trainings- und Testdaten nach 80 Epochen?\n",
    "1. Ändern Sie jetzt die Batch-Größe und trainieren Sie das Neuronale Netz in 1. für die Batch-Größen `batch_sizes = [32, 128, 512, 1024, 15000]`. Visualisieren Sie die Verläufe der Kosten für Training und Test. Interpretieren Sie das Ergebnis. Wie ändert sich das Lernverhalten bei den einzelnen Batch-Größen?\n",
    "1. Verändern Sie die Lernrate und trainieren das Neuronale Netz für unterschiedliche Lernraten (und die in 5. gegebenen Batch-Sizes). Probieren Sie in jedem Fall auch die Lernraten 0.0001 und 0.1 aus. Beschreiben Sie die Veränderung und ggf. Gründe für das veränderte Lernverhalten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lösung Aufgabe 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Parameter\n",
    "learning_rate = 0.001\n",
    "n_epochs = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ihre Löung ab hier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Loader\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data,\n",
    "    batch_size=len(test_data), shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teil 1: Neurnales Netz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the net structure\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.neuralnet = nn.Sequential(\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),                    \n",
    "            nn.Linear(16,8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8,1)\n",
    "        ) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.neuralnet(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teil 2: train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for each epoch\n",
    "\n",
    "def train(network, train_loader):\n",
    "    \n",
    "  # Loop over the batches\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "    # --- Steps of the training of the net ---\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teil 3: Calculation of loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Loss\n",
    "def calc_loss(network, data_loader):\n",
    "    network.eval()  # Modell in den Evaluierungsmodus versetzen\n",
    "    criterion = nn.MSELoss()  # Mean Squared Error (L2 Loss)\n",
    "    \n",
    "    total_loss = 0\n",
    "    with torch.no_grad():  # Keine Gradientenberechnung\n",
    "        for inputs, targets in data_loader:\n",
    "            outputs = network(inputs)  # Vorwärtsdurchlauf\n",
    "            loss = criterion(outputs, targets)  # Verlust berechnen\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teil 4: Train net via Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teil 5: Different Batch-Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [32, 128, 512, 1024, 15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Teil 6: Different Learning Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Rate: 0.0001**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Rate: 0.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2 (Batch-Size und Learnrate) [6 Punkte]\n",
    "Das folgende Bild zeigt die Lernkurve der Kosten beim Training eines Neuronalen Netzes. Betrachten Sie jetzt die Bilder a)-c). Wie haben sich jeweils Lernrate oder Batch-Größe geändert, so dass der Verlauf der Loss-Kurve jeweils den angegeben Verlauf hat? Begründen Sie Ihre Antwort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./Bilder_Blatt1/A2_initialerLoss.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss mit Änderungen in Batch-Größe oder Lernrate**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)\n",
    "\n",
    "![](./Bilder_Blatt1/A2_loss_a.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\n",
    "\n",
    "![](./Bilder_Blatt1/A2_loss_b.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c)\n",
    "\n",
    "![](./Bilder_Blatt1/A2_loss_c.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lösung Aufgabe 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
