{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # \"Header\"\n",
    "\n",
    "<p style=\"text-align: left;  font-size:18pt; LINE-HEIGHT:30px;\">\n",
    "    <span style=\"float: left\">\n",
    "     Technische Hochschule Ingolstadt<br>\n",
    "     Prof. Dr. Sören Gröttrup\n",
    "    </span>\n",
    "    <span style=\"float: right;\">\n",
    "       Machine Learning 2<br>\n",
    "        <span style=\"float: right;\">SS 2025</span>\n",
    "    </span>\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # \"Header Aufgabenblatt\"\n",
    "<br>\n",
    "<p style=\"text-align: center;  font-size:18pt; LINE-HEIGHT:30px;\">\n",
    "     <span style=\"font-weight: bold;\">Aufgabenblatt 3</span><br>\n",
    "     Themen: Weight Initialization, Batch Normalisierung<br>\n",
    "     Abgabetermin: 08.05.2025<br>\n",
    "     Punkte: 25\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Namen:** _Bitte tragen Sie hier die Namen der Abgabegruppe ein._\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten\n",
    "\n",
    "Der Datensatz `fashion-mnist` ist ein von Zalando bereitgestellter Datensatz und enthält Bilder von Kleidungsstücken aus 10 verschiedenen Kategorien (https://github.com/zalandoresearch/fashion-mnist).\n",
    "\n",
    "Der Datensatz besteht aus einem Trainigsdatensatz mit 60.000 Bildern und einem Testdatensatz mit 10.000 Bildern. Jedes Bild ist ein grauskaliertes 28x28 Bild und die 10 Klassen sind mit 0 bis 9 codiert. \n",
    "Die Codierung ist in der nachfolgenden Tabelle angegeben:\n",
    "\n",
    "|Label| Description|\n",
    "| --- | --- |\n",
    "|0| T-shirt/top|\n",
    "|1| Trouser|\n",
    "|2| Pullover|\n",
    "|3| Dress|\n",
    "|4| Coat|\n",
    "|5| Sandal|\n",
    "|6| Shirt|\n",
    "|7| Sneaker|\n",
    "|8| Bag|\n",
    "|9| Ankle boot|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import time\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1 [17 Punkte]\n",
    "\n",
    "Ziel der Aufgabe ist es sich mit der Normalisierung der Input Variablen und der Initialisierung der Gewichte vertraut zu machen und dies zu implementieren.\n",
    "\n",
    "1. Schreiben Sie einen Routine, welche das unten angegebene Neuronale Netz `Net()` mittels `F.nll_loss()` trainiert. Dabei soll während des Trainings die Accuracy des jeweiligen Batches in regelmäßigem Abstand berechnet und abgespeichert werden (alle `log_interval` Iterationen). Weiter soll nach jeder Epoche der Loss und die Accuracy des gesamten Testdatensatzes berechnet und abgespeichert werden. \n",
    "\n",
    "1. Trainieren Sie das Neuronale Netz mittels SGD auf dem Datensatz und visualisieren Sie die Ergebnisse. \n",
    "\n",
    "1. Beim Laden der Daten werden die Inputs automatisch auf das Intervall [0,1] skaliert. Fügen Sie beim Laden der Bilder den befehl `torchvision.transforms.Normalize(0.5, 0.5)` ein. Dieser skaliert die Inputs auf das Intervall [-1,1] und zentriert diese so. Trainieren Sie das Neuronale Netz erneut, visualisieren Sie die Ergebnisse und vergleichen es mit dem Training ohne zentrierte Inputs. Beschreiben Sie die Veränderungen (falls vorhanden). \n",
    "\n",
    "1. Informieren Sie sich darüber, wie man in PyTorch die Gewichte initialisieren kann. Fügen Sie dann dem Neuronalen Netz eine geeignete Initalisierung der Gewichte hinzu und trainieren Sie dieses dann erneut. Vergleichen Sie es mit den anderen Trainingverläufen und visualisieren Sie diese. \n",
    "\n",
    "1. Informieren Sie sich, wie man in PyTorch Batch-Normalisierung hinzufügen kann. Fügen Sie dem Netz an den geeigneten Stellen Batch-Normalisierung hinzu und trainieren Sie dieses erneut. Vergleichen Sie es mit den anderen Trainigsverläufen und visualisieren Sie diese. \n",
    "_Hinweis:_ Sie können das Training beschleunigen, in dem Sie im DataLoader die Option `num_workers` auf eine positive Zahl setzen (z.B. `num_workers=4`). Dies beschleunigt das Laden der einzelnen Daten für die Mini-Batches. Mehr Informationen hier: https://pytorch.org/docs/stable/data.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "download_data_to_folder = \"../Data/\"\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "log_interval = 200\n",
    "n_epochs = 10\n",
    "\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train data MNIST\n",
    "\n",
    "# Define Transformer (ToTensor() is a must)\n",
    "transformer = torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Define data to download\n",
    "train_data = torchvision.datasets.FashionMNIST(download_data_to_folder, train=True, download=True, transform=transformer)\n",
    "test_data = torchvision.datasets.FashionMNIST(download_data_to_folder, train=False, download=True, transform=transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data in one batch!\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  train_data,\n",
    "  batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Loader\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  test_data,\n",
    "  batch_size=batch_size_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize iterator\n",
    "train_iter = iter(train_loader)\n",
    "data, targets = next(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = train_data[1][0].view(-1).shape[0]\n",
    "print(\"Number of inpu variables (pixel):\", input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "n = 5 # number of images\n",
    "start_pos = 0\n",
    "for i in range(n):\n",
    "  plt.subplot(1, n, i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(data[i+start_pos][0], cmap='gray', interpolation='none')\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuronal Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the net structure\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.fc1 = nn.Linear(input_size, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, input_size)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginn Ihrer Lösung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train and Test Funktionen**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for each epoch\n",
    "\n",
    "def train(epoch, network):\n",
    "  ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function that applies the test set to the trained net\n",
    "\n",
    "def test(network):\n",
    "  ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_nn(network):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2 [8 Punkte]\n",
    "\n",
    "Trainieren Sie nun das Neuronale Netze aus Aufgabe 1 Teil 4 (mit Weight Initialization) und trainieren dies \n",
    "\n",
    "1. mit Momentum\n",
    "1. mit Adam\n",
    "\n",
    "jeweils mit den Default Parametern. Hat sich etwas am Trainingsverlauf geändert?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginn Ihrer Lösung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
