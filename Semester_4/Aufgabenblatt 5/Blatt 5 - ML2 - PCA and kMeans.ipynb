{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # \"Header\"\n",
    "\n",
    "<p style=\"text-align: left;  font-size:18pt; LINE-HEIGHT:30px;\">\n",
    "    <span style=\"float: left\">\n",
    "     Technische Hochschule Ingolstadt<br>\n",
    "     Prof. Dr. Sören Gröttrup & Laura Dietl\n",
    "    </span>\n",
    "    <span style=\"float: right;\">\n",
    "       Machine Learning 2<br>\n",
    "        <span style=\"float: right;\">SS 2025</span>\n",
    "    </span>\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[//]: # \"Header Aufgabenblatt\"\n",
    "<br>\n",
    "<p style=\"text-align: center;  font-size:18pt; LINE-HEIGHT:30px;\">\n",
    "     <span style=\"font-weight: bold;\">Aufgabenblatt 5</span><br>\n",
    "     Themen: Dimensionsreduktionsverfahren, k-Means Clustering<br>\n",
    "     Abgabetermin: 12.06.2024, 23:59 Uhr<br>\n",
    "     Punkte: 30\n",
    "</p>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Namen:** Emelie Hauck, Conrad Christoph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 1 [16 Punkte]"
   ]
  },
  {
   "attachments": {
    "74164b53-b137-40fa-9ac4-9ff8ebf5f467.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten\n",
    "\n",
    "Der Datensatz `fashion-mnist` ist ein von Zalando bereitgestellter Datensatz und enthält Bilder von Kleidungsstücken aus 10 verschiedenen Kategorien (https://github.com/zalandoresearch/fashion-mnist).\n",
    "\n",
    "![grafik.png](attachment:74164b53-b137-40fa-9ac4-9ff8ebf5f467.png)\n",
    "\n",
    "\n",
    "Der Datensatz besteht aus einem Trainigsdatensatz mit 60.000 Bildern und einem Testdatensatz mit 10.000 Bildern. Jedes Bild ist ein grauskaliertes 28x28 Bild und die 10 Klassen sind mit 0 bis 9 codiert. \n",
    "Die Codierung ist in der nachfolgenden Tabelle angegeben:\n",
    "\n",
    "|Label| Description|\n",
    "| --- | --- |\n",
    "|0| T-shirt/top|\n",
    "|1| Trouser|\n",
    "|2| Pullover|\n",
    "|3| Dress|\n",
    "|4| Coat|\n",
    "|5| Sandal|\n",
    "|6| Shirt|\n",
    "|7| Sneaker|\n",
    "|8| Bag|\n",
    "|9| Ankle boot|\n",
    "\n",
    "Der _fashion-minst_ Datensatz ist enthalten in der Biliothek `torchvision` und kann mittels `torchvision.datasets.FashionMNIST` aufgerufen werden."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methode: Hauptkomponentenanalyse\n",
    "In dieser Aufgaben sollen Sie eine Hauptkomponentenanalyse (PCA) auf den obigen Datensatz anwenden. Bei der Hauptkomponentenanalyse werden die Input-Feature in neue Feature, die Hauptkomponenten, linear transformiert. Die Hauptkomponenten sind dabei so gewählt, dass diese alle senkrecht aufeinander stehen, sie sind also unkorreliert zueinander. Die Informationen, welche die Hauptkomponenten tragen, sind also anschaulich nicht voneinander abhängig. Desweiteren werden die Hauptkomponenten so konstruiert, dass die erste Hauptkomponente die größte Variation der Daten wiederspiegelt (sie enthält also die meiste Information), die zweite Hauptkomponente die zweitgrößte Variation (zweit meisten Informationen) usw.. Durch diese Eigenschaft wird die Hauptkomponentenanalyse auch für die Dimensionsreduktion der Input-Feature verwendet. Anstatt alle Input-Feature zu nehmen, kann man auch nur die ersten $n$ Hauptkomponenten als Inputs wählen, da diese den Großteil der Informationen der Daten enthalten.\n",
    "\n",
    "\n",
    "\n",
    "### Aufgabe\n",
    "Laden Sie dazu jeweils den Trainingsdatensatz  und den Testdatensatz in die Variablen `train_data` und `test_data`. Benutzen Sie dabei auch den folgenden angegebenen Transformer. Achtung: Sie müssen noch den Pfad \"download_data_to_folder\" angeben, in welchen die Daten geladen werden sollen:<br><br>\n",
    "```python\n",
    "#### Load data ####\n",
    "download_data_to_folder = ....\n",
    "\n",
    "transformer = torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "train_data = torchvision.datasets.FashionMNIST(download_data_to_folder, train=True, download=True, transform=transformer)\n",
    "test_data = torchvision.datasets.FashionMNIST(download_data_to_folder, train=False, download=True, transform=transformer)\n",
    "```\n",
    "<br>\n",
    "\n",
    "1. In PyTorch können Sie mittels der Funktion `torch.pca_lowrank` eine Hauptkomponentenanalyse durchführen. Dabei werden die Matrizen, welche für die lineare Transformation benötigt werden berechnet und ausgegeben. Informieren Sie sich genauer über die Funktionsweise dieser Funktion und führen dann eine Hauptkomponentenanalyse auf den Trainingsdaten durch. Visualisieren Sie die Daten in einem 2D-Scatterplot der ersten beiden Hauptkomponenten. Erkennen Sie irgendwelche Muster?\n",
    "\n",
    "1. Visualisieren Sie den Anteil der erklärten Varianz in Bezug auf die verwendete Anzahl an Hauptkomponenten. Wieviele Hauptkomponenten brauchen Sie um 90% der Varianz zu behalten (zu erklären)?\n",
    "\n",
    "1. Trainieren Sie das unten definierte Neuronale Netz einmal für die reduzierten Daten (Input sind die in 2. ermittelten Hauptkomponenten, welche 90% der Varianz beschreiben) und die original Daten unter Berücksichtigung der vordefinierten Parameter und Funktionen sowie des Optimizers SGD. Messen Sie jeweils die Dauer des Trainings über 20 Epochen. Was sind Loss und Accuracy auf dem Testdatensatz? _Hinweis_: Um die vordfinierten Funktionen `train()` und `test()` anwenden zu können, müssen Sie die Daten (insb. den Output der PCA) in einen DataLoader transformieren. Sie können dafür die Funktion `toDataLoader()` nutzen.\n",
    "\n",
    "\n",
    "1. Sie können die Matrizen aus der Funktion `torch.pca_lowrank` auch verwenden, um aus den Hauptkomponenten wieder auf das Originalbild zu schließen. So rekonstruieren Sie das Bild aus weniger Informationen. Rekonstruieren Sie die Bilder für die in der Teilaufgabe 2) ermittele Anzahl an ersten Hauptkomponenten für 90% der Varianz. Visualisieren Sie einige der rekonstruierten Bilder. Sind die Kleidungsstücke zu erkennen?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load packages and set parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "\n",
    "import time\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b4b1d3f390>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define Parameters\n",
    "n_epochs = 20\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "learning_rate = 0.01\n",
    "log_interval = 100\n",
    "\n",
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predifined Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# components and targets to data loader\n",
    "def toDataLoader(components, targets, test_ind=False):\n",
    "    batch_size = batch_size_train\n",
    "    if (test_ind):\n",
    "        batch_size = batch_size_test\n",
    "        \n",
    "    feature_target = torch.utils.data.TensorDataset(components, targets)\n",
    "    new_loader = torch.utils.data.DataLoader(\n",
    "      feature_target,\n",
    "      batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    return new_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot images\n",
    "# data: Bilddaten in folgendem Format [Anzahl Bilder, Pixel, Pixel]\n",
    "# n_img: Anzahl an Bildern, die geplottet werden sollen\n",
    "def plot_images(data, n_img):\n",
    "  n = n_img # number of images\n",
    "  start_pos = 0\n",
    "  plt.figure(figsize=(20,20))\n",
    "  for i in range(n):\n",
    "    plt.subplot(1, n, i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(data[i+start_pos], cmap='gray', interpolation='none')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the net structure\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_vars):\n",
    "        super(Net, self).__init__()\n",
    "        self.input_vars = input_vars\n",
    "        self.fc1 = nn.Linear(self.input_vars, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_vars)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function for each epoch\n",
    "\n",
    "def train(epoch, network, train_loader):\n",
    "  network.train()\n",
    "  \n",
    "  # Loop over the batches\n",
    "  for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    \n",
    "    # --- Steps of the training of the net ---\n",
    "    optimizer.zero_grad()\n",
    "    output = network(data)\n",
    "    loss = F.nll_loss(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # --- Output & Evaluation metrics ---\n",
    "    if batch_idx % log_interval == 0:\n",
    "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "        epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "        100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function that applies the test set to the trained net\n",
    "\n",
    "def test(network, test_loader):\n",
    "  network.eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  \n",
    "  # Gradient calculation is disabled (as not needed)\n",
    "  with torch.no_grad():\n",
    "    \n",
    "    # Loop over the batches\n",
    "    for data, target in test_loader:\n",
    "        \n",
    "      # --- Prediction and calculation of evaluation metrics ---\n",
    "      output = network(data)\n",
    "      test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "   \n",
    "  # --- Output ---\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung ab hier"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-Means Clustering\n",
    "\n",
    "**k-Means Clustering** ist eines der bekanntesten Clusterverfehren. Für eine gegebene natürliche Zahl $k$ findet der Algorithmus $k$ Cluster indem er die $k$ Clustermittelpunkte, die so genannten **Zentroide (centrooids)** mittels eines iterativen Verfahrens identifiziert. Die Zentroide definieren die Cluster, indem ein Datenpunkt demjenigen Cluster zugeordent wird, zu dessen Zentroid er den geringsten Abstand hat.\n",
    "\n",
    "Detailliertere Informationen zum k-Means Clustering in der Vorlesung.\n",
    "\n",
    "#### PyTorch\n",
    "\n",
    "In PyTorch ist k-Means im dem Paket `kmeans_pytorch` implementiert. https://github.com/subhadarship/kmeans_pytorch/\n",
    "\n",
    "_Installation_: `$ pip install kmeans-pytorch`\n",
    "\n",
    "Die Funktion `kmeans_pytorch.kmeans(X=, num_clusters=, distance='euclidean')` führt für eine angegebene Anzahl an Clustern $num\\_clusters$ auf der flachen Tabelle $X$ ein k-means Clustering durch. Dabei sind die Zeilen die Samples und die Spalten die unterschiedlichen Variablen. Über die Option `distance=` können unterschiedliche Metriken angegeben werden. Der Default ist die euklidische Metrik.\n",
    "\n",
    "_Output_: Als Output gibt die Funktion einen Tensor der Clusterzugehörigkeit für jeden Datenpunkt zurück, sowie die Koordinaten der Zentroide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufgabe 2 [14 Punkte]\n",
    "\n",
    "\n",
    "1. Führen Sie ein k-means Clustering für `num_clusters=10` auf den Originaldaten (Trainingsdaten) des FashionMNIST Datensatzes durch. Wie groß sind die einzelnen Cluster (wie viele Sample sind in den einzelnen Clustern)?\n",
    "\n",
    "1. Die Zentroide sind die Repräsentanten der Cluster. Plotten Sie die Bilder der Zentroide. Transformieren Sie dazu zuerst die Zentroide zurück in 28x28 Format. D.h. in einen 3-dimensionalen Tensor der Größe `torch.Size([10, 28, 28])`. Wenden Sie dann die Funktion `plot_images` darauf an. Welche unterschiedlichen Objekte hat der Algorithmus gefunden?\n",
    "\n",
    "1. Führen Sie nun nochmal ein k-means Clustering für `num_clusters=4` bzw. `num_clusters=12` durch. Wie sehen die gefundenen Objekte nun aus?\n",
    "\n",
    "1. Führen Sie ein k-means Clustering für `num_clusters=10` auf den in Aufgabe 1 durch PCA reduzierte Daten durch (auf den gefundenen Hauptkomponenten, dei 90% der Varianz beschreiben) des FashionMNIST Datensatzes durch. Vergleichen Sie das Clustering mit dem in 1. mittels des Silhoutte-Scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lösung ab hier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
